# Data_Preprocessing
## 📁 Repository Structure
- `cleaned_data.csv`: The final, analysis-ready dataset.
- `Data_preprocessing.ipynb`: The notebook with all cleaning steps.
- `Titanic-dataset`: Dataset from kaggle which is cleaned and preprocessed

## ✨ Cleaning Steps Performed
- Handled missing values by...
- Corrected data types for columns like...
- Removed duplicate entries.
- Standardized text formats in categorical columns.

## 🛠️ How to Run
1. Clone the repository: `git clone <YOUR_GITHUB_REPO_URL.git>`
2. Install dependencies: `pip install -r requirements.txt`
3. Open and run the notebook located in the `notebooks/` folder.
